# Text Mining and Network Analysis Project Documentation

## Project Overview
This project demonstrates the implementation of text mining and network analysis techniques using Python. It processes and analyzes social media data to extract insights, identify patterns, and visualize relationships within the text.

## Dataset Description
The sample dataset consists of social media posts (tweets/comments) about the iPhone 17, containing various opinions, features discussions, and user experiences. This dataset was chosen because it:
- Contains natural language expressions
- Includes sentiment variations (positive and negative opinions)
- Has identifiable topics and themes
- Contains mentions and hashtags for network analysis
- Represents real-world social media discourse

## Technical Architecture

### 1. Text Mining Component

#### A. Text Preprocessing Pipeline
- **Tokenization**: Breaks text into individual words/tokens
- **Case Normalization**: Converts all text to lowercase
- **Stop Word Removal**: Eliminates common words like "the", "is", "at"
- **Lemmatization**: Reduces words to their base form (e.g., "running" â†’ "run")

#### B. Text Analysis Techniques
1. **TF-IDF Vectorization**
   - Converts text into numerical format
   - Weights terms based on their importance in documents
   - Enables mathematical analysis of text data

2. **Document Clustering**
   - Uses K-means algorithm
   - Groups similar documents together
   - Identifies main content categories

3. **Topic Modeling (LDA)**
   - Discovers abstract topics in document collection
   - Provides topic distribution per document
   - Helps understand main themes in the dataset

4. **Sentiment Analysis**
   - Measures emotional tone of texts
   - Provides polarity scores (-1 to 1)
   - Identifies customer satisfaction levels

### 2. Network Analysis Component

#### A. Network Construction
- Creates word co-occurrence network
- Nodes represent words
- Edges represent relationships between words
- Edge weights indicate relationship strength

#### B. Network Metrics
1. **Basic Metrics**
   - Node count
   - Edge count
   - Average degree
   - Network density

2. **Centrality Measures**
   - Degree Centrality: Identifies most connected words
   - Betweenness Centrality: Finds bridge words
   - Helps identify key terms and concepts

3. **Community Detection**
   - Identifies word clusters
   - Shows related term groups
   - Reveals topic structure

## Visualization Components
1. **Sentiment Distribution**
   - Histogram of sentiment scores
   - Shows opinion distribution
   - Identifies general sentiment trends

2. **Network Graph**
   - Interactive network visualization
   - Node size indicates importance
   - Edge thickness shows relationship strength
   - Color coding for communities

## Required Dependencies
```
nltk==3.8.1
pandas==2.0.0
numpy==1.24.3
scikit-learn==1.2.2
gensim==4.3.1
networkx==3.1
textblob==0.17.1
seaborn==0.12.2
matplotlib==3.7.1
```

## Usage Instructions

### 1. Setup
1. Install required packages:
   ```bash
   pip install -r requirements.txt
   ```
2. Download NLTK data:
   ```python
   import nltk
   nltk.download(['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger'])
   ```

### 2. Running the Analysis
1. Text Mining:
   - Run preprocessing
   - Execute TF-IDF vectorization
   - Perform clustering and topic modeling
   - Analyze sentiments

2. Network Analysis:
   - Generate word network
   - Calculate network metrics
   - Detect communities
   - Create visualizations

## Output Interpretation

### 1. Text Mining Results
- **Clustering**: Documents grouped by similarity
- **Topics**: Main themes in the dataset
- **Sentiment Scores**: Opinion polarity measurements

### 2. Network Analysis Results
- **Centrality Scores**: Important words/concepts
- **Community Structure**: Related term groups
- **Network Metrics**: Dataset relationship patterns

## Limitations and Considerations
1. **Dataset Size**
   - Sample size affects result reliability
   - Larger datasets may need more processing time

2. **Language Limitations**
   - Currently optimized for English
   - May need adaptation for other languages

3. **Processing Requirements**
   - Large networks may need significant memory
   - Complex analyses may require optimization

## Future Enhancements
1. Multi-language support
2. Advanced preprocessing options
3. Additional visualization types
4. Real-time processing capabilities
5. Interactive dashboard integration

## Troubleshooting
1. Memory Issues:
   - Reduce dataset size
   - Implement batch processing
   
2. Performance Optimization:
   - Use sparse matrices
   - Implement parallel processing

## References and Resources
1. NLTK Documentation
2. NetworkX Documentation
3. Scikit-learn Documentation
4. Gensim LDA Documentation
